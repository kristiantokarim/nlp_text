{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import feature_extract\n",
    "from keras.models import Sequential\n",
    "from gensim.models import KeyedVectors\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Conv1D, MaxPool1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classlabaelencoder(y):\n",
    "\tencoder = LabelEncoder()\n",
    "\tencoder.fit(y)\n",
    "\ty_encoded = encoder.transform(y)\n",
    "\treturn np_utils.to_categorical(y_encoded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp_text/feature_extract.py:192: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  list_features.append(np.dot(q1, q2)/(np.linalg.norm(q1)* np.linalg.norm(q2)))\n"
     ]
    }
   ],
   "source": [
    "dataset = feature_extract.readCSV('train.csv')\n",
    "used = dataset[5000:15000]\n",
    "\n",
    "f_dataset = feature_extract.remove_shared_word(used)\n",
    "f_dataset = feature_extract.normalize_sentence_dataset(f_dataset)\n",
    "f_dataset = feature_extract.lemmatize_sentence_dataset(f_dataset)\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300-SLIM.bin'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for data in f_dataset:\n",
    "    x_train.append(feature_extract.get_features(data,w2v_model))\n",
    "    y_train.append(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50000\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.6197 - acc: 0.6419 - val_loss: nan - val_acc: 0.6743\n",
      "Epoch 2/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.6058 - acc: 0.6672 - val_loss: nan - val_acc: 0.6723\n",
      "Epoch 3/50000\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.5930 - acc: 0.6781 - val_loss: nan - val_acc: 0.6723\n",
      "Epoch 4/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.5851 - acc: 0.6837 - val_loss: nan - val_acc: 0.6953\n",
      "Epoch 5/50000\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.5707 - acc: 0.6948 - val_loss: nan - val_acc: 0.7120\n",
      "Epoch 6/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.5631 - acc: 0.7039 - val_loss: nan - val_acc: 0.7075\n",
      "Epoch 7/50000\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.5558 - acc: 0.7071 - val_loss: nan - val_acc: 0.7105\n",
      "Epoch 8/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.5465 - acc: 0.7189 - val_loss: nan - val_acc: 0.7163\n",
      "Epoch 9/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.5366 - acc: 0.7231 - val_loss: nan - val_acc: 0.7190\n",
      "Epoch 10/50000\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.5308 - acc: 0.7275 - val_loss: nan - val_acc: 0.7163\n",
      "Epoch 11/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.5260 - acc: 0.7292 - val_loss: nan - val_acc: 0.7140\n",
      "Epoch 12/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.5202 - acc: 0.7358 - val_loss: nan - val_acc: 0.7232\n",
      "Epoch 13/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.5162 - acc: 0.7413 - val_loss: nan - val_acc: 0.7232\n",
      "Epoch 14/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.5090 - acc: 0.7441 - val_loss: nan - val_acc: 0.7282\n",
      "Epoch 15/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.5081 - acc: 0.7481 - val_loss: nan - val_acc: 0.7255\n",
      "Epoch 16/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.5012 - acc: 0.7501 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 17/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4945 - acc: 0.7587 - val_loss: nan - val_acc: 0.7260\n",
      "Epoch 18/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4916 - acc: 0.7574 - val_loss: nan - val_acc: 0.7270\n",
      "Epoch 19/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4871 - acc: 0.7613 - val_loss: nan - val_acc: 0.7250\n",
      "Epoch 20/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4839 - acc: 0.7658 - val_loss: nan - val_acc: 0.7245\n",
      "Epoch 21/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4785 - acc: 0.7704 - val_loss: nan - val_acc: 0.7332\n",
      "Epoch 22/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4743 - acc: 0.7720 - val_loss: nan - val_acc: 0.7245\n",
      "Epoch 23/50000\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4685 - acc: 0.7717 - val_loss: nan - val_acc: 0.7222\n",
      "Epoch 24/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4637 - acc: 0.7784 - val_loss: nan - val_acc: 0.7230\n",
      "Epoch 25/50000\n",
      "8000/8000 [==============================] - 2s 256us/step - loss: 0.4589 - acc: 0.7820 - val_loss: nan - val_acc: 0.7205\n",
      "Epoch 26/50000\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.4565 - acc: 0.7887 - val_loss: nan - val_acc: 0.7228\n",
      "Epoch 27/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4516 - acc: 0.7873 - val_loss: nan - val_acc: 0.7240\n",
      "Epoch 28/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4520 - acc: 0.7879 - val_loss: nan - val_acc: 0.7275\n",
      "Epoch 29/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4474 - acc: 0.7886 - val_loss: nan - val_acc: 0.7218\n",
      "Epoch 30/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4417 - acc: 0.7948 - val_loss: nan - val_acc: 0.7300\n",
      "Epoch 31/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4317 - acc: 0.8008 - val_loss: nan - val_acc: 0.7252\n",
      "Epoch 32/50000\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.4306 - acc: 0.7969 - val_loss: nan - val_acc: 0.7265\n",
      "Epoch 33/50000\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.4273 - acc: 0.8052 - val_loss: nan - val_acc: 0.7238\n",
      "Epoch 34/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4268 - acc: 0.8019 - val_loss: nan - val_acc: 0.7392\n",
      "Epoch 35/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4256 - acc: 0.8060 - val_loss: nan - val_acc: 0.7285\n",
      "Epoch 36/50000\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.4151 - acc: 0.8111 - val_loss: nan - val_acc: 0.7325\n",
      "Epoch 37/50000\n",
      "8000/8000 [==============================] - 2s 242us/step - loss: 0.4096 - acc: 0.8186 - val_loss: nan - val_acc: 0.7268\n",
      "Epoch 38/50000\n",
      "8000/8000 [==============================] - 2s 260us/step - loss: 0.4106 - acc: 0.8152 - val_loss: nan - val_acc: 0.7300\n",
      "Epoch 39/50000\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.4045 - acc: 0.8214 - val_loss: nan - val_acc: 0.7280\n",
      "Epoch 40/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.4013 - acc: 0.8235 - val_loss: nan - val_acc: 0.7242\n",
      "Epoch 41/50000\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4027 - acc: 0.8207 - val_loss: nan - val_acc: 0.7215\n",
      "Epoch 42/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3922 - acc: 0.8261 - val_loss: nan - val_acc: 0.7312\n",
      "Epoch 43/50000\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3926 - acc: 0.8281 - val_loss: nan - val_acc: 0.7258\n",
      "Epoch 44/50000\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3891 - acc: 0.8346 - val_loss: nan - val_acc: 0.7298\n",
      "Epoch 45/50000\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3831 - acc: 0.8312 - val_loss: nan - val_acc: 0.7258\n",
      "Epoch 46/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3826 - acc: 0.8348 - val_loss: nan - val_acc: 0.7328\n",
      "Epoch 47/50000\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3789 - acc: 0.8345 - val_loss: nan - val_acc: 0.7382\n",
      "Epoch 48/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.3736 - acc: 0.8388 - val_loss: nan - val_acc: 0.7240\n",
      "Epoch 49/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.3731 - acc: 0.8409 - val_loss: nan - val_acc: 0.7350\n",
      "Epoch 50/50000\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3674 - acc: 0.8428 - val_loss: nan - val_acc: 0.7395\n",
      "Epoch 51/50000\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 0.3599 - acc: 0.8462 - val_loss: nan - val_acc: 0.7315\n",
      "Epoch 52/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3597 - acc: 0.8476 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 53/50000\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3567 - acc: 0.8512 - val_loss: nan - val_acc: 0.7348\n",
      "Epoch 54/50000\n",
      "8000/8000 [==============================] - 2s 242us/step - loss: 0.3551 - acc: 0.8493 - val_loss: nan - val_acc: 0.7338\n",
      "Epoch 55/50000\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3548 - acc: 0.8506 - val_loss: nan - val_acc: 0.7300\n",
      "Epoch 56/50000\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3433 - acc: 0.8596 - val_loss: nan - val_acc: 0.7272\n",
      "Epoch 57/50000\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.3476 - acc: 0.8505 - val_loss: nan - val_acc: 0.7338\n",
      "Epoch 58/50000\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3443 - acc: 0.8559 - val_loss: nan - val_acc: 0.7322\n",
      "Epoch 59/50000\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3430 - acc: 0.8544 - val_loss: nan - val_acc: 0.7328\n",
      "Epoch 60/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.3380 - acc: 0.8559 - val_loss: nan - val_acc: 0.7340\n",
      "Epoch 61/50000\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.3282 - acc: 0.8622 - val_loss: nan - val_acc: 0.7258\n",
      "Epoch 62/50000\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3311 - acc: 0.8654 - val_loss: nan - val_acc: 0.7305\n",
      "Epoch 63/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3215 - acc: 0.8682 - val_loss: nan - val_acc: 0.7338\n",
      "Epoch 64/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3212 - acc: 0.8691 - val_loss: nan - val_acc: 0.7350\n",
      "Epoch 65/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3132 - acc: 0.8733 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 66/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3152 - acc: 0.8748 - val_loss: nan - val_acc: 0.7340\n",
      "Epoch 67/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3119 - acc: 0.8732 - val_loss: nan - val_acc: 0.7308\n",
      "Epoch 68/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3073 - acc: 0.8754 - val_loss: nan - val_acc: 0.7330\n",
      "Epoch 69/50000\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.3085 - acc: 0.8760 - val_loss: nan - val_acc: 0.7368\n",
      "Epoch 70/50000\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3037 - acc: 0.8750 - val_loss: nan - val_acc: 0.7315\n",
      "Epoch 71/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3037 - acc: 0.8785 - val_loss: nan - val_acc: 0.7348\n",
      "Epoch 72/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2968 - acc: 0.8835 - val_loss: nan - val_acc: 0.7365\n",
      "Epoch 73/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2958 - acc: 0.8805 - val_loss: nan - val_acc: 0.7368\n",
      "Epoch 74/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2918 - acc: 0.8850 - val_loss: nan - val_acc: 0.7348\n",
      "Epoch 75/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2921 - acc: 0.8810 - val_loss: nan - val_acc: 0.7328\n",
      "Epoch 76/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2835 - acc: 0.8851 - val_loss: nan - val_acc: 0.7320\n",
      "Epoch 77/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2780 - acc: 0.8936 - val_loss: nan - val_acc: 0.7332\n",
      "Epoch 78/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2826 - acc: 0.8926 - val_loss: nan - val_acc: 0.7330\n",
      "Epoch 79/50000\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.2790 - acc: 0.8929 - val_loss: nan - val_acc: 0.7325\n",
      "Epoch 80/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2808 - acc: 0.8915 - val_loss: nan - val_acc: 0.7318\n",
      "Epoch 81/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2782 - acc: 0.8897 - val_loss: nan - val_acc: 0.7315\n",
      "Epoch 82/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.2762 - acc: 0.8939 - val_loss: nan - val_acc: 0.7352\n",
      "Epoch 83/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.2753 - acc: 0.8942 - val_loss: nan - val_acc: 0.7318\n",
      "Epoch 84/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.2663 - acc: 0.9008 - val_loss: nan - val_acc: 0.7348\n",
      "Epoch 85/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2672 - acc: 0.8952 - val_loss: nan - val_acc: 0.7318\n",
      "Epoch 86/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2580 - acc: 0.9031 - val_loss: nan - val_acc: 0.7358\n",
      "Epoch 87/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.2623 - acc: 0.8942 - val_loss: nan - val_acc: 0.7365\n",
      "Epoch 88/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2591 - acc: 0.9001 - val_loss: nan - val_acc: 0.7382\n",
      "Epoch 89/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.2572 - acc: 0.9024 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 90/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.2589 - acc: 0.9014 - val_loss: nan - val_acc: 0.7310\n",
      "Epoch 91/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2553 - acc: 0.9002 - val_loss: nan - val_acc: 0.7345\n",
      "Epoch 92/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2512 - acc: 0.9059 - val_loss: nan - val_acc: 0.7320\n",
      "Epoch 93/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.2478 - acc: 0.9068 - val_loss: nan - val_acc: 0.7400\n",
      "Epoch 94/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.2437 - acc: 0.9043 - val_loss: nan - val_acc: 0.7305\n",
      "Epoch 95/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2459 - acc: 0.9065 - val_loss: nan - val_acc: 0.7292\n",
      "Epoch 96/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2372 - acc: 0.9079 - val_loss: nan - val_acc: 0.7325\n",
      "Epoch 97/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2353 - acc: 0.9139 - val_loss: nan - val_acc: 0.7330\n",
      "Epoch 98/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2344 - acc: 0.9116 - val_loss: nan - val_acc: 0.7325\n",
      "Epoch 99/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2369 - acc: 0.9128 - val_loss: nan - val_acc: 0.7350\n",
      "Epoch 100/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2365 - acc: 0.9141 - val_loss: nan - val_acc: 0.7305\n",
      "Epoch 101/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2268 - acc: 0.9179 - val_loss: nan - val_acc: 0.7378\n",
      "Epoch 102/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2233 - acc: 0.9171 - val_loss: nan - val_acc: 0.7350\n",
      "Epoch 103/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2304 - acc: 0.9161 - val_loss: nan - val_acc: 0.7370\n",
      "Epoch 104/50000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.2280 - acc: 0.9150 - val_loss: nan - val_acc: 0.7345\n",
      "Epoch 105/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.2188 - acc: 0.9158 - val_loss: nan - val_acc: 0.7365\n",
      "Epoch 106/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2222 - acc: 0.9183 - val_loss: nan - val_acc: 0.7372\n",
      "Epoch 107/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2186 - acc: 0.9199 - val_loss: nan - val_acc: 0.7320\n",
      "Epoch 108/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.2149 - acc: 0.9203 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 109/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2128 - acc: 0.9220 - val_loss: nan - val_acc: 0.7345\n",
      "Epoch 110/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2179 - acc: 0.9206 - val_loss: nan - val_acc: 0.7328\n",
      "Epoch 111/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.2099 - acc: 0.9232 - val_loss: nan - val_acc: 0.7380\n",
      "Epoch 112/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.2096 - acc: 0.9230 - val_loss: nan - val_acc: 0.7330\n",
      "Epoch 113/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2119 - acc: 0.9209 - val_loss: nan - val_acc: 0.7310\n",
      "Epoch 114/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.2061 - acc: 0.9243 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 115/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2020 - acc: 0.9235 - val_loss: nan - val_acc: 0.7312\n",
      "Epoch 116/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.2080 - acc: 0.9224 - val_loss: nan - val_acc: 0.7338\n",
      "Epoch 117/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.1968 - acc: 0.9308 - val_loss: nan - val_acc: 0.7328\n",
      "Epoch 118/50000\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.2014 - acc: 0.9273 - val_loss: nan - val_acc: 0.7348\n",
      "Epoch 119/50000\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.1919 - acc: 0.9322 - val_loss: nan - val_acc: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/50000\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.2045 - acc: 0.9240 - val_loss: nan - val_acc: 0.7320\n",
      "Epoch 121/50000\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.1969 - acc: 0.9301 - val_loss: nan - val_acc: 0.7362\n",
      "Epoch 122/50000\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.1913 - acc: 0.9298 - val_loss: nan - val_acc: 0.7360\n",
      "Epoch 123/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.1858 - acc: 0.9324 - val_loss: nan - val_acc: 0.7370\n",
      "Epoch 124/50000\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.1914 - acc: 0.9314 - val_loss: nan - val_acc: 0.7345\n",
      "Epoch 125/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.1867 - acc: 0.9306 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 126/50000\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.1900 - acc: 0.9345 - val_loss: nan - val_acc: 0.7268\n",
      "Epoch 127/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.1896 - acc: 0.9307 - val_loss: nan - val_acc: 0.7358\n",
      "Epoch 128/50000\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.1793 - acc: 0.9349 - val_loss: nan - val_acc: 0.7370\n",
      "Epoch 129/50000\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.1801 - acc: 0.9373 - val_loss: nan - val_acc: 0.7372\n",
      "Epoch 130/50000\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.1802 - acc: 0.9356 - val_loss: nan - val_acc: 0.7355\n",
      "Epoch 131/50000\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.1803 - acc: 0.9344 - val_loss: nan - val_acc: 0.7362\n",
      "Epoch 132/50000\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.1759 - acc: 0.9390 - val_loss: nan - val_acc: 0.7370\n",
      "Epoch 133/50000\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.1761 - acc: 0.9373 - val_loss: nan - val_acc: 0.7330\n",
      "Epoch 134/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.1710 - acc: 0.9408 - val_loss: nan - val_acc: 0.7400\n",
      "Epoch 135/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.1740 - acc: 0.9394 - val_loss: nan - val_acc: 0.7385\n",
      "Epoch 136/50000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.1796 - acc: 0.9365 - val_loss: nan - val_acc: 0.7382\n",
      "Epoch 137/50000\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.1727 - acc: 0.9373 - val_loss: nan - val_acc: 0.7352\n",
      "Epoch 138/50000\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.1704 - acc: 0.9398 - val_loss: nan - val_acc: 0.7360\n",
      "Epoch 139/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.1727 - acc: 0.9363 - val_loss: nan - val_acc: 0.7375\n",
      "Epoch 140/50000\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.1705 - acc: 0.9384 - val_loss: nan - val_acc: 0.7360\n",
      "Epoch 141/50000\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.1704 - acc: 0.9391 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 142/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.1600 - acc: 0.9449 - val_loss: nan - val_acc: 0.7370\n",
      "Epoch 143/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.1692 - acc: 0.9384 - val_loss: nan - val_acc: 0.7402\n",
      "Epoch 144/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.1589 - acc: 0.9455 - val_loss: nan - val_acc: 0.7372\n",
      "Epoch 145/50000\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.1631 - acc: 0.9426 - val_loss: nan - val_acc: 0.7388\n",
      "Epoch 146/50000\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.1612 - acc: 0.9418 - val_loss: nan - val_acc: 0.7378\n",
      "Epoch 147/50000\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.1626 - acc: 0.9428 - val_loss: nan - val_acc: 0.7375\n",
      "Epoch 148/50000\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.1614 - acc: 0.9434 - val_loss: nan - val_acc: 0.7375\n",
      "Epoch 149/50000\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.1626 - acc: 0.9442 - val_loss: nan - val_acc: 0.7342\n",
      "Epoch 150/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.1601 - acc: 0.9441 - val_loss: nan - val_acc: 0.7362\n",
      "Epoch 151/50000\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.1592 - acc: 0.9427 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 152/50000\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.1495 - acc: 0.9460 - val_loss: nan - val_acc: 0.7358\n",
      "Epoch 153/50000\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.1564 - acc: 0.9456 - val_loss: nan - val_acc: 0.7332\n",
      "Epoch 154/50000\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.1483 - acc: 0.9502 - val_loss: nan - val_acc: 0.7340\n",
      "Epoch 155/50000\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.1555 - acc: 0.9427 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 156/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.1489 - acc: 0.9494 - val_loss: nan - val_acc: 0.7345\n",
      "Epoch 157/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.1530 - acc: 0.9441 - val_loss: nan - val_acc: 0.7325\n",
      "Epoch 158/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.1479 - acc: 0.9466 - val_loss: nan - val_acc: 0.7322\n",
      "Epoch 159/50000\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.1492 - acc: 0.9457 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 160/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.1500 - acc: 0.9487 - val_loss: nan - val_acc: 0.7315\n",
      "Epoch 161/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.1514 - acc: 0.9446 - val_loss: nan - val_acc: 0.7365\n",
      "Epoch 162/50000\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.1467 - acc: 0.9500 - val_loss: nan - val_acc: 0.7358\n",
      "Epoch 163/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.1475 - acc: 0.9479 - val_loss: nan - val_acc: 0.7352\n",
      "Epoch 164/50000\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.1415 - acc: 0.9491 - val_loss: nan - val_acc: 0.7342\n",
      "Epoch 165/50000\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.1449 - acc: 0.9486 - val_loss: nan - val_acc: 0.7375\n",
      "Epoch 166/50000\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.1419 - acc: 0.9510 - val_loss: nan - val_acc: 0.7335\n",
      "Epoch 167/50000\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.1401 - acc: 0.9529 - val_loss: nan - val_acc: 0.7358\n",
      "Epoch 168/50000\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.1386 - acc: 0.9531 - val_loss: nan - val_acc: 0.7332\n",
      "Epoch 169/50000\n",
      "6240/8000 [======================>.......] - ETA: 0s - loss: 0.1423 - acc: 0.9499"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=len(x_train[0]), units=150, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adagrad(), metrics=['accuracy'])\n",
    "model.fit(x_train, classlabaelencoder(y_train), epochs=50000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used = dataset[0:2000]\n",
    "\n",
    "f_dataset = feature_extract.remove_shared_word(used)\n",
    "f_dataset = feature_extract.normalize_sentence_dataset(f_dataset)\n",
    "f_dataset = feature_extract.lemmatize_sentence_dataset(f_dataset)\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300-SLIM.bin'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for data in f_dataset:\n",
    "    x_train.append(feature_extract.get_features(data,w2v_model))\n",
    "    y_train.append(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = model.predict(x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
